{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio  \n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np  \n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import numpy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def load_data():\n",
    "    \n",
    "    faces = np.empty((700, 165 * 120))\n",
    "    label = np.zeros((700, 100))\n",
    "\n",
    "    data=sio.loadmat('AR_database.mat')\n",
    "\n",
    "    Tr_dataMatrix = data['Tr_dataMatrix'].astype('float32')/256\n",
    "    Tr_sampleLabels = data['Tr_sampleLabels'].astype('float32')\n",
    "    Tt_dataMatrix = data['Tt_dataMatrix'].astype('float32')/256\n",
    "    Tt_sampleLabels = data['Tt_sampleLabels'].astype('float32')\n",
    "\n",
    "    faces = np.empty((1400, 165 * 120))\n",
    "\n",
    "    train_data = Tr_dataMatrix.T\n",
    "    train_label = np.zeros((700, 100))\n",
    "    for i in range(100):\n",
    "        train_label[i * 7: (i + 1) * 7, i] = 1\n",
    "\n",
    "    test_data = Tt_dataMatrix.T\n",
    "    test_label = np.zeros((700, 100))\n",
    "    for i in range(100):\n",
    "         test_label[i * 7: (i + 1) * 7, i] = 1\n",
    "    face = np.concatenate((train_data,test_data),axis=0)\n",
    "    label = np.concatenate((train_label,test_label),axis=0)\n",
    "    \n",
    "    train_data = np.empty((1120, 165*120))\n",
    "    train_label = np.zeros((1120, 100))\n",
    "    vaild_data = np.empty((200, 165 * 120))\n",
    "    vaild_label = np.zeros((200, 100))\n",
    "    test_data = np.empty((200, 165 * 120))\n",
    "    test_label = np.zeros((200, 100))\n",
    "    \n",
    "    \n",
    "    for i in range(200):\n",
    "        train_data[i * 5: i * 5 + 5] = face[i * 7: i * 7 + 5]\n",
    "        train_label[i * 5: i * 5 + 5] = label[i * 7: i * 7 + 5]\n",
    "\n",
    "        vaild_data[i] = face[i * 7 + 5]\n",
    "        vaild_label[i] = label[i * 7 + 5]\n",
    "\n",
    "        test_data[i] = face[i * 7 + 6]\n",
    "        test_label[i] = label[i * 7 + 6]\n",
    "        \n",
    "    train_data = train_data.astype('float32')\n",
    "    vaild_data = vaild_data.astype('float32')\n",
    "    test_data = test_data.astype('float32')\n",
    "\n",
    "    return [\n",
    "        (train_data, train_label),\n",
    "        (vaild_data, vaild_label),\n",
    "        (test_data, test_label)\n",
    "    ]\n",
    "'''\n",
    "def load_face():\n",
    "    data=sio.loadmat('AR_buzhedang.mat')\n",
    "    Tr_dataMatrix = data['O_Tt_DAT'].T.astype('float32')/256\n",
    "    Tr_sampleLabels = data['trls'].astype('float32')\n",
    "    dat=Tr_dataMatrix\n",
    "    label = np.zeros((700, 100))\n",
    "    for i in range(100):\n",
    "        label[i * 7: (i + 1) * 7, i] = 1\n",
    "        \n",
    "    faces = np.empty((700, 57 * 47))\n",
    "    \n",
    "    for i in range(700):\n",
    "        bbb = dat[:][i]\n",
    "        grid = [[0]*57]*47\n",
    "        bbb.resize((47,57))\n",
    "        grid = bbb.T\n",
    "        g2 = [[0]*2679]*1\n",
    "        matrix_a = np.array(g2)\n",
    "        matrix_a = matrix_a.astype('float32')\n",
    "        g=0\n",
    "        for j in range(57):\n",
    "            for k in range(47):\n",
    "                matrix_a[0][g]=grid[j][k]\n",
    "                g=g+1\n",
    "        faces[i][:]= matrix_a\n",
    "        \n",
    "    #print faces.shape\n",
    "    label1 = np.zeros((200,40))\n",
    "    for i in range(40):\n",
    "        label1[i*5:(i+1)*5,i]=1\n",
    "        \n",
    "    label2 = np.zeros((40,40))\n",
    "    for i in range(40):\n",
    "        label2[i,i]=1\n",
    "        \n",
    "\n",
    "    train_data = np.empty((500, 57 * 47))\n",
    "    train_label = np.zeros((500, 100))\n",
    "    vaild_data = np.empty((100, 57 * 47))\n",
    "    vaild_label = np.zeros((100, 100))\n",
    "    test_data = np.empty((100, 57 * 47))\n",
    "    test_label = np.zeros((100, 100))\n",
    "\n",
    "    for i in range(100):\n",
    "        train_data[i * 5: i * 5 + 5] = faces[i * 7+2: i * 7 + 7]\n",
    "        train_label[i * 5: i * 5 + 5] = label[i * 7+2: i * 7 + 7]\n",
    "\n",
    "        vaild_data[i] = faces[i * 7]\n",
    "        vaild_label[i] = label[i * 7 + 5]\n",
    "\n",
    "        test_data[i] = faces[i * 7+1 ]\n",
    "        test_label[i] = label[i * 7 + 6]\n",
    "\n",
    "    train_data = train_data.astype('float32')\n",
    "    vaild_data = vaild_data.astype('float32')\n",
    "    test_data = test_data.astype('float32')\n",
    "\n",
    "    '''\n",
    "    return [\n",
    "        (train_data[0:200][:], train_label[0:200]),\n",
    "        (vaild_data[0:40][:], vaild_label[0:40]),\n",
    "        (test_data[0:40][:], test_label[0:40])\n",
    "    ]\n",
    "    '''\n",
    "    return [\n",
    "        (train_data[0:200][:], label1),\n",
    "        (vaild_data[0:40][:], label2),\n",
    "        (test_data[0:40][:], label2)\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Y=', <tf.Tensor 'Placeholder_1:0' shape=(40, 40) dtype=float32>)\n",
      "('vec:=====:', <tf.Tensor 'full_connection/Flatten/Reshape:0' shape=(40, 11520) dtype=float32>)\n",
      "('vec:=====:', <tf.Tensor 'full_connection/Relu:0' shape=(40, 1024) dtype=float32>)\n",
      "(40, 40)\n",
      "(0, ' : ', 1798208.078125)\n",
      "create the directory: ./model\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(1, ' : ', 747435.1171875)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(2, ' : ', 334399.0625)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(3, ' : ', 142672.294921875)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(4, ' : ', 68015.68798828125)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(5, ' : ', 39425.1435546875)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(6, ' : ', 23843.647216796875)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(7, ' : ', 13712.248229980469)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(8, ' : ', 8168.864990234375)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(9, ' : ', 4292.5559539794922)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(10, ' : ', 2149.8984603881836)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(11, ' : ', 871.37430572509766)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(12, ' : ', 281.60839939117432)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(13, ' : ', 37.945140838623047)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(14, ' : ', 27.350061416625977)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(15, ' : ', 50.94390869140625)\n",
      "(16, ' : ', 1.1231811046600342)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(17, ' : ', 0.0)\n",
      "Model saved in file: ./model/best.ckpt\n",
      "(18, ' : ', 0.038511782884597778)\n",
      "(19, ' : ', 0.0)\n",
      "(20, ' : ', 0.0)\n",
      "(21, ' : ', 3.9338755186690832e-07)\n",
      "(22, ' : ', 0.0)\n",
      "(23, ' : ', 2.9802320611338473e-09)\n",
      "(24, ' : ', 2.9802320611338473e-09)\n",
      "INFO:tensorflow:Restoring parameters from ./model/best.ckpt\n",
      "('valid set accuracy: ', 0.77499998)\n",
      "picture person is 9, but mis-predicted as person 17\n",
      "picture person is 13, but mis-predicted as person 14\n",
      "picture person is 18, but mis-predicted as person 0\n",
      "picture person is 21, but mis-predicted as person 35\n",
      "picture person is 23, but mis-predicted as person 14\n",
      "picture person is 27, but mis-predicted as person 38\n",
      "picture person is 30, but mis-predicted as person 26\n",
      "picture person is 31, but mis-predicted as person 37\n",
      "picture person is 33, but mis-predicted as person 35\n",
      "picture person is 34, but mis-predicted as person 39\n",
      "picture person is 35, but mis-predicted as person 31\n",
      "picture person is 39, but mis-predicted as person 34\n"
     ]
    }
   ],
   "source": [
    "def convolutional_layer(data, kernel_size, bias_size, pooling_size):\n",
    "    kernel = tf.get_variable(\"conv\", kernel_size, initializer=tf.random_normal_initializer())\n",
    "    bias = tf.get_variable('bias', bias_size, initializer=tf.random_normal_initializer())\n",
    "\n",
    "    conv = tf.nn.conv2d(data, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    linear_output = tf.nn.relu(tf.add(conv, bias))\n",
    "    pooling = tf.nn.max_pool(linear_output, ksize=pooling_size, strides=pooling_size, padding=\"SAME\")\n",
    "    return pooling\n",
    "\n",
    "def linear_layer(data, weights_size, biases_size):\n",
    "    weights = tf.get_variable(\"weigths\", weights_size, initializer=tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(\"biases\", biases_size, initializer=tf.random_normal_initializer())\n",
    "    return tf.add(tf.matmul(data, weights), biases)\n",
    "\n",
    "def convolutional_neural_network(data):\n",
    "    # 根据类别个数定义最后输出层的神经元\n",
    "    n_ouput_layer = 40\n",
    "\n",
    "    kernel_shape1=[5, 5, 1, 32]\n",
    "    kernel_shape2=[5, 5, 32, 64]\n",
    "    full_conn_w_shape = [15 * 12 * 64, 1024]\n",
    "    out_w_shape = [1024, n_ouput_layer]\n",
    "\n",
    "    bias_shape1=[32]\n",
    "    bias_shape2=[64]\n",
    "    full_conn_b_shape = [1024]\n",
    "    out_b_shape = [n_ouput_layer]\n",
    "\n",
    "    data = tf.reshape(data, [-1, 57, 47, 1])\n",
    "\n",
    "    # 经过第一层卷积神经网络后，得到的张量shape为：[batch, 29, 24, 32]\n",
    "    with tf.variable_scope(\"conv_layer1\") as layer1:\n",
    "        layer1_output = convolutional_layer(\n",
    "            data=data,\n",
    "            kernel_size=kernel_shape1,\n",
    "            bias_size=bias_shape1,\n",
    "            pooling_size=[1, 2, 2, 1]\n",
    "        )\n",
    "    # 经过第二层卷积神经网络后，得到的张量shape为：[batch, 15, 12, 64]\n",
    "    with tf.variable_scope(\"conv_layer2\") as layer2:\n",
    "        layer2_output = convolutional_layer(\n",
    "            data=layer1_output,\n",
    "            kernel_size=kernel_shape2,\n",
    "            bias_size=bias_shape2,\n",
    "            pooling_size=[1, 2, 2, 1]\n",
    "        )\n",
    "    with tf.variable_scope(\"full_connection\") as full_layer3:\n",
    "        # 讲卷积层张量数据拉成2-D张量只有有一列的列向量\n",
    "        layer2_output_flatten = tf.contrib.layers.flatten(layer2_output)\n",
    "        print(\"vec:=====:\",layer2_output_flatten)\n",
    "        layer3_output = tf.nn.relu(\n",
    "            linear_layer(\n",
    "                data=layer2_output_flatten,\n",
    "                weights_size=full_conn_w_shape,\n",
    "                biases_size=full_conn_b_shape\n",
    "            )\n",
    "        )\n",
    "        print(\"vec:=====:\",layer3_output)\n",
    "        # layer3_output = tf.nn.dropout(layer3_output, 0.8)\n",
    "    with tf.variable_scope(\"output\") as output_layer4:\n",
    "        output = linear_layer(\n",
    "            data=layer3_output,\n",
    "            weights_size=out_w_shape,\n",
    "            biases_size=out_b_shape\n",
    "        )\n",
    "    print output.shape\n",
    "\n",
    "    return output;\n",
    "\n",
    "def train_facedata(dataset, model_dir,model_path):\n",
    "    # train_set_x = data[0][0]\n",
    "    # train_set_y = data[0][1]\n",
    "    # valid_set_x = data[1][0]\n",
    "    # valid_set_y = data[1][1]\n",
    "    # test_set_x = data[2][0]\n",
    "    # test_set_y = data[2][1]\n",
    "    # X = tf.placeholder(tf.float32, shape=(None, None), name=\"x-input\")  # 输入数据\n",
    "    # Y = tf.placeholder(tf.float32, shape=(None, None), name='y-input')  # 输入标签\n",
    "\n",
    "    batch_size = 40\n",
    "\n",
    "    # train_set_x, train_set_y = dataset[0]\n",
    "    # valid_set_x, valid_set_y = dataset[1]\n",
    "    # test_set_x, test_set_y = dataset[2]\n",
    "    train_set_x = dataset[0][0]\n",
    "    train_set_y = dataset[0][1]\n",
    "    valid_set_x = dataset[1][0]\n",
    "    valid_set_y = dataset[1][1]\n",
    "    test_set_x = dataset[2][0]\n",
    "    test_set_y = dataset[2][1]\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [batch_size, 57 * 47])\n",
    "    Y = tf.placeholder(tf.float32, [batch_size, 40])\n",
    "    print(\"Y=\",Y)\n",
    "\n",
    "    predict = convolutional_neural_network(X)\n",
    "    cost_func = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer(1e-2).minimize(cost_func)\n",
    "\n",
    "    # 用于保存训练的最佳模型\n",
    "    saver = tf.train.Saver()\n",
    "    #model_dir = './model'\n",
    "    #model_path = model_dir + '/best.ckpt'\n",
    "    with tf.Session() as session:\n",
    "        # 若不存在模型数据，需要训练模型参数\n",
    "        if not os.path.exists(model_path + \".index\"):\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            best_loss = float('Inf')\n",
    "            for epoch in range(25):\n",
    "                epoch_loss = 0\n",
    "                for i in range((int)(np.shape(train_set_x)[0] / batch_size)):\n",
    "                    x = train_set_x[i * batch_size: (i + 1) * batch_size]\n",
    "                    y = train_set_y[i * batch_size: (i + 1) * batch_size]\n",
    "                    _, cost = session.run([optimizer, cost_func], feed_dict={X: x, Y: y})\n",
    "                    epoch_loss += cost\n",
    "\n",
    "                print(epoch, ' : ', epoch_loss)\n",
    "                if best_loss > epoch_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    if not os.path.exists(model_dir):\n",
    "                        os.mkdir(model_dir)\n",
    "                        print(\"create the directory: %s\" % model_dir)\n",
    "                    save_path = saver.save(session, model_path)\n",
    "                    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "        # 恢复数据并校验和测试\n",
    "        saver.restore(session, model_path)\n",
    "        correct = tf.equal(tf.argmax(predict,1), tf.argmax(Y,1))\n",
    "        valid_accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        print('valid set accuracy: ', valid_accuracy.eval({X: valid_set_x, Y: valid_set_y}))\n",
    "\n",
    "        test_pred = tf.argmax(predict, 1).eval({X: test_set_x})\n",
    "        test_true = np.argmax(test_set_y, 1)\n",
    "        test_correct = correct.eval({X: test_set_x, Y: test_set_y})\n",
    "        incorrect_index = [i for i in range(np.shape(test_correct)[0]) if not test_correct[i]]\n",
    "        for i in incorrect_index:\n",
    "            print('picture person is %i, but mis-predicted as person %i'\n",
    "                %(test_true[i], test_pred[i]))\n",
    "        #plot_errordata(incorrect_index)\n",
    "\n",
    "#画出在测试集中错误的数据\n",
    "def plot_errordata(error_index):\n",
    "    data[2][0][:][error_index]\n",
    "    pig=data.resize((57,47))\n",
    "    plt.show(pig)\n",
    "\n",
    "def main():\n",
    "    dataset_path = \"olivettifaces.gif\"\n",
    "    data = load_face()\n",
    "    model_dir = './model'\n",
    "    model_path = model_dir + '/best.ckpt'\n",
    "    train_facedata(data, model_dir, model_path)\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
