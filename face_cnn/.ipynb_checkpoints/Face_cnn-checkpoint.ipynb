{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio  \n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np  \n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import numpy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    faces = np.empty((1400, 165 * 120))\n",
    "    label = np.zeros((1400, 100))\n",
    "\n",
    "    data=sio.loadmat('AR_database.mat')\n",
    "\n",
    "    Tr_dataMatrix = data['Tr_dataMatrix']/256\n",
    "    Tr_sampleLabels = data['Tr_sampleLabels']/256\n",
    "    Tt_dataMatrix = data['Tt_dataMatrix']/256\n",
    "    Tt_sampleLabels = data['Tt_sampleLabels']/256\n",
    "\n",
    "    faces = np.empty((1400, 165 * 120))\n",
    "\n",
    "    train_data = Tr_dataMatrix.T\n",
    "    train_label = np.zeros((700, 100))\n",
    "    for i in range(100):\n",
    "        train_label[i * 7: (i + 1) * 7, i] = 1\n",
    "\n",
    "    test_data = Tt_dataMatrix.T\n",
    "    test_label = np.zeros((700, 100))\n",
    "    for i in range(100):\n",
    "         test_label[i * 7: (i + 1) * 7, i] = 1\n",
    "    face = np.concatenate((train_data,test_data),axis=0)\n",
    "    label = np.concatenate((train_label,test_label),axis=0)\n",
    "    \n",
    "    train_data = np.empty((1120, 165*120))\n",
    "    train_label = np.zeros((1120, 100))\n",
    "    vaild_data = np.empty((200, 165 * 120))\n",
    "    vaild_label = np.zeros((200, 100))\n",
    "    test_data = np.empty((200, 165 * 120))\n",
    "    test_label = np.zeros((200, 100))\n",
    "    \n",
    "    \n",
    "    for i in range(200):\n",
    "        train_data[i * 5: i * 5 + 5] = face[i * 7: i * 7 + 5]\n",
    "        train_label[i * 5: i * 5 + 5] = label[i * 7: i * 7 + 5]\n",
    "\n",
    "        vaild_data[i] = face[i * 7 + 5]\n",
    "        vaild_label[i] = label[i * 7 + 5]\n",
    "\n",
    "        test_data[i] = face[i * 7 + 6]\n",
    "        test_label[i] = label[i * 7 + 6]\n",
    "        \n",
    "    train_data = train_data.astype('float32')\n",
    "    vaild_data = vaild_data.astype('float32')\n",
    "    test_data = test_data.astype('float32')\n",
    "\n",
    "    return [(train_data, train_label),(vaild_data, vaild_label),(test_data, test_label)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Y=', <tf.Tensor 'Placeholder_1:0' shape=(200, 100) dtype=float32>)\n",
      "('vec:=====:', <tf.Tensor 'full_connection/Flatten/Reshape:0' shape=(200, 80640) dtype=float32>)\n",
      "('vec:=====:', <tf.Tensor 'full_connection/Relu:0' shape=(200, 1024) dtype=float32>)\n",
      "(200, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convolutional_layer(data, kernel_size, bias_size, pooling_size):\n",
    "    kernel = tf.get_variable(\"conv\", kernel_size, initializer=tf.random_normal_initializer())\n",
    "    bias = tf.get_variable('bias', bias_size, initializer=tf.random_normal_initializer())\n",
    "\n",
    "    conv = tf.nn.conv2d(data, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    linear_output = tf.nn.relu(tf.add(conv, bias))\n",
    "    pooling = tf.nn.max_pool(linear_output, ksize=pooling_size, strides=pooling_size, padding=\"SAME\")\n",
    "    return pooling\n",
    "\n",
    "def linear_layer(data, weights_size, biases_size):\n",
    "    weights = tf.get_variable(\"weigths\", weights_size, initializer=tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(\"biases\", biases_size, initializer=tf.random_normal_initializer())\n",
    "    return tf.add(tf.matmul(data, weights), biases)\n",
    "\n",
    "def convolutional_neural_network(data):\n",
    "    # 根据类别个数定义最后输出层的神经元\n",
    "    n_ouput_layer = 100\n",
    "\n",
    "    kernel_shape1=[5, 5, 1, 32]\n",
    "    kernel_shape2=[5, 5, 32, 64]\n",
    "    full_conn_w_shape = [80640, 1024]\n",
    "    out_w_shape = [1024, n_ouput_layer]\n",
    "\n",
    "    bias_shape1=[32]\n",
    "    bias_shape2=[64]\n",
    "    full_conn_b_shape = [1024]\n",
    "    out_b_shape = [n_ouput_layer]\n",
    "\n",
    "    data = tf.reshape(data, [-1, 165, 120, 1])\n",
    "\n",
    "    # 经过第一层卷积神经网络后，得到的张量shape为：[batch, 29, 24, 32]\n",
    "    with tf.variable_scope(\"conv_layer1\") as layer1:\n",
    "        layer1_output = convolutional_layer(\n",
    "            data=data,\n",
    "            kernel_size=kernel_shape1,\n",
    "            bias_size=bias_shape1,\n",
    "            pooling_size=[1, 2, 2, 1]\n",
    "        )\n",
    "    # 经过第二层卷积神经网络后，得到的张量shape为：[batch, 15, 12, 64]\n",
    "    with tf.variable_scope(\"conv_layer2\") as layer2:\n",
    "        layer2_output = convolutional_layer(\n",
    "            data=layer1_output,\n",
    "            kernel_size=kernel_shape2,\n",
    "            bias_size=bias_shape2,\n",
    "            pooling_size=[1, 2, 2, 1]\n",
    "        )\n",
    "    with tf.variable_scope(\"full_connection\") as full_layer3:\n",
    "        # 讲卷积层张量数据拉成2-D张量只有有一列的列向量\n",
    "        layer2_output_flatten = tf.contrib.layers.flatten(layer2_output)\n",
    "        print(\"vec:=====:\",layer2_output_flatten)\n",
    "        layer3_output = tf.nn.relu(\n",
    "            linear_layer(\n",
    "                data=layer2_output_flatten,\n",
    "                weights_size=full_conn_w_shape,\n",
    "                biases_size=full_conn_b_shape\n",
    "            )\n",
    "        )\n",
    "        print(\"vec:=====:\",layer3_output)\n",
    "        # layer3_output = tf.nn.dropout(layer3_output, 0.8)\n",
    "    with tf.variable_scope(\"output\") as output_layer4:\n",
    "        output = linear_layer(\n",
    "            data=layer3_output,\n",
    "            weights_size=out_w_shape,\n",
    "            biases_size=out_b_shape\n",
    "        )\n",
    "    print output.shape\n",
    "\n",
    "    return output;\n",
    "\n",
    "def train_facedata(dataset, model_dir,model_path):\n",
    "    # train_set_x = data[0][0]\n",
    "    # train_set_y = data[0][1]\n",
    "    # valid_set_x = data[1][0]\n",
    "    # valid_set_y = data[1][1]\n",
    "    # test_set_x = data[2][0]\n",
    "    # test_set_y = data[2][1]\n",
    "    # X = tf.placeholder(tf.float32, shape=(None, None), name=\"x-input\")  # 输入数据\n",
    "    # Y = tf.placeholder(tf.float32, shape=(None, None), name='y-input')  # 输入标签\n",
    "\n",
    "    batch_size = 200\n",
    "\n",
    "    # train_set_x, train_set_y = dataset[0]\n",
    "    # valid_set_x, valid_set_y = dataset[1]\n",
    "    # test_set_x, test_set_y = dataset[2]\n",
    "    train_set_x = dataset[0][0]\n",
    "    train_set_y = dataset[0][1]\n",
    "    valid_set_x = dataset[1][0]\n",
    "    valid_set_y = dataset[1][1]\n",
    "    test_set_x = dataset[2][0]\n",
    "    test_set_y = dataset[2][1]\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [batch_size, 165*120])\n",
    "    Y = tf.placeholder(tf.float32, [batch_size, 100])\n",
    "    print(\"Y=\",Y)\n",
    "\n",
    "    predict = convolutional_neural_network(X)\n",
    "    cost_func = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer(1e-2).minimize(cost_func)\n",
    "\n",
    "    # 用于保存训练的最佳模型\n",
    "    saver = tf.train.Saver()\n",
    "    #model_dir = './model'\n",
    "    #model_path = model_dir + '/best.ckpt'\n",
    "    with tf.Session() as session:\n",
    "        # 若不存在模型数据，需要训练模型参数\n",
    "        if not os.path.exists(model_path + \".index\"):\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            best_loss = float('Inf')\n",
    "            for epoch in range(30):\n",
    "                epoch_loss = 0\n",
    "                for i in range((int)(np.shape(train_set_x)[0] / batch_size)):\n",
    "                    x = train_set_x[i * batch_size: (i + 1) * batch_size]\n",
    "                    y = train_set_y[i * batch_size: (i + 1) * batch_size]\n",
    "                    _, cost = session.run([optimizer, cost_func], feed_dict={X: x, Y: y})\n",
    "                    epoch_loss += cost\n",
    "\n",
    "                print(epoch, ' : ', epoch_loss)\n",
    "                if best_loss > epoch_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    if not os.path.exists(model_dir):\n",
    "                        os.mkdir(model_dir)\n",
    "                        print(\"create the directory: %s\" % model_dir)\n",
    "                    save_path = saver.save(session, model_path)\n",
    "                    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "        # 恢复数据并校验和测试\n",
    "        saver.restore(session, model_path)\n",
    "        correct = tf.equal(tf.argmax(predict,1), tf.argmax(Y,1))\n",
    "        valid_accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        print('valid set accuracy: ', valid_accuracy.eval({X: valid_set_x, Y: valid_set_y}))\n",
    "\n",
    "        test_pred = tf.argmax(predict, 1).eval({X: test_set_x})\n",
    "        test_true = np.argmax(test_set_y, 1)\n",
    "        test_correct = correct.eval({X: test_set_x, Y: test_set_y})\n",
    "        incorrect_index = [i for i in range(np.shape(test_correct)[0]) if not test_correct[i]]\n",
    "        for i in incorrect_index:\n",
    "            print('picture person is %i, but mis-predicted as person %i'\n",
    "                %(test_true[i], test_pred[i]))\n",
    "        #plot_errordata(incorrect_index, \"olivettifaces.gif\")\n",
    "\n",
    "#画出在测试集中错误的数据\n",
    "def plot_errordata(error_index, dataset_path):\n",
    "    img = mpimg.imread(dataset_path)\n",
    "    plt.imshow(img)\n",
    "    currentAxis = plt.gca()\n",
    "    for index in error_index:\n",
    "        row = index // 2\n",
    "        column = index % 2\n",
    "        currentAxis.add_patch(\n",
    "            patches.Rectangle(\n",
    "                xy=(\n",
    "                     47 * 9 if column == 0 else 47 * 19,\n",
    "                     row * 57\n",
    "                    ),\n",
    "                width=47,\n",
    "                height=57,\n",
    "                linewidth=1,\n",
    "                edgecolor='r',\n",
    "                facecolor='none'\n",
    "            )\n",
    "    )\n",
    "    plt.savefig(\"result.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = load_data()\n",
    "    model_dir = './model'\n",
    "    model_path = model_dir + '/best.ckpt'\n",
    "    train_facedata(data, model_dir, model_path)\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
